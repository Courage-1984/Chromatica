# -----------------------------------------------------------------------------
# Chromatica Project Rules - .cursorrules
# -----------------------------------------------------------------------------
# This file directs the AI assistant to adhere to the consolidated plan for
# the color search engine project, as detailed in ./docs/.cursor/critical_instructions.md.
# All generated code, architectural decisions, and suggestions must strictly
# follow these guidelines.
# -----------------------------------------------------------------------------

behavior:
  # The AI must always prioritize the instructions in the critical_instructions.md file.
  # This document is the single source of truth for the project.
  # Before generating any code or making a suggestion, the AI must state:
  # "Consulting critical_instructions.md..."
  pre-response-directive: "Consulting critical_instructions.md..."

  # When asked to implement a feature, always refer to the relevant section
  # (e.g., "Section D. Algorithm specification") to ensure complete alignment.
  # Do not improvise on core architectural components.
  # If a detail is missing, ask for clarification rather than making an assumption.
  strictness: high

# The directory and file structure for the project.
file-layout:
  - path: src/chromatica/
    description: "Main source code for the Chromatica application."
  - path: src/chromatica/core/
    description: "Core logic for color space conversion, histogram generation, and distance metrics."
  - path: src/chromatica/indexing/
    description: "Scripts and modules for the offline indexing pipeline (processing images, building the FAISS index)."
  - path: src/chromatica/api/
    description: "FastAPI application, including endpoints, request/response models."
  - path: src/chromatica/utils/
    description: "Utility functions, configuration management, and helper scripts."
  - path: scripts/
    description: "Standalone scripts for tasks like bulk indexing, evaluation, and data downloading."
  - path: data/
    description: "Placeholder for image datasets (e.g., Unsplash Lite, COCO subset)."
  - path: notebooks/
    description: "Jupyter notebooks for experimentation, analysis, and visualization."
  - path: tests/
    description: "Unit and integration tests for the application."
  - path: docs/
    description: "Project documentation, including progress reports and troubleshooting guides."
  - path: docs/.cursor/critical_instructions.md
    description: "The primary project plan. This is the source of truth."
  - path: tools/
    description: "Testing and development tools, including histogram generation testing tool."
  - path: datasets/
    description: "Comprehensive test datasets for development and validation across all phases: test-dataset-20 (20 images), test-dataset-50 (50 images), test-dataset-200 (200 images), test-dataset-5000 (5,000 images, renamed from test-dataset-999, recommended expansion to 7,500 for production-scale testing)."

rules:
  # General Rules
  - rule: "Always adhere to the consolidated plan in ./docs/.cursor/critical_instructions.md."
  - rule: "Use Python 3.10+ with type hints for all new code."
  - rule: "Follow the PEP 8 style guide for all Python code."

  # Documentation and Commenting Rules
  - rule: "All functions, classes, and modules must have Google-style docstrings."
  - rule: "Ensure all code is well-commented, especially complex algorithmic sections, to explain the 'why' behind the code."
  - rule: "Maintain a project-level README.md with setup instructions and an overview."
  - rule: "Maintain a progress report in 'docs/progress.md', updating it after major phases."
  - rule: "Create and update a troubleshooting guide in 'docs/troubleshooting.md' as issues are identified and resolved."

  # Technology Stack Rules
  - rule: "Use 'opencv-python' for image loading and resizing."
  - rule: "Use 'scikit-image' specifically for the sRGB to CIE Lab color conversion."
  - rule: "Use 'numpy' for all numerical operations, especially for vectorized histogram generation."
  - rule: "Use 'faiss-cpu' for the ANN index. The specific index must be 'IndexHNSWFlat' as specified in Section C."
  - rule: "Use the 'POT' (Python Optimal Transport) library for the Sinkhorn-EMD reranking stage."
  - rule: "Use 'DuckDB' for storing metadata and raw histograms. Do not use other databases unless specified."
  - rule: "The web API must be built using 'FastAPI'."

  # Algorithmic Specification Rules
  - rule: "The color space for all processing MUST be CIE Lab (D65 illuminant)."
  - rule: "The histogram binning grid MUST be 8x12x12 (L* a* b*) for a total of 1,152 dimensions."
  - rule: "Implement tri-linear soft assignment for histogram generation as described in Section D."
  - rule: "The embedding for the ANN index MUST be created by applying an element-wise square root (Hellinger transform) to the normalized histogram."
  - rule: "The final reranking distance metric MUST be the Sinkhorn-approximated Earth Mover's Distance (EMD)."
  - rule: "The cost matrix (M) for the Sinkhorn-EMD calculation must be pre-computed based on the squared Euclidean distance between bin centers in Lab space."

  # API & Configuration Rules
  - rule: "Implement the REST endpoint 'GET /search' exactly as defined in Section H, including all query parameters and the JSON response structure."
  - rule: "Key constants (bin sizes, color ranges, rerank K) should be stored in a central configuration file or module (e.g., src/chromatica/utils/config.py)."

  # Tool Usage Rules
  - rule: "Use the 'filesystem' tool for all file and directory manipulations as requested in prompts."
  - rule: "When researching external information, library documentation, or error solutions, use the 'brave-search' or 'gitmcp-docs' tools to find relevant information."
  - rule: "When needing to understand the current state of the repository, use 'gitmvp' tools like 'get_file_tree' or 'read_repository'."
  - rule: "When encountering a new library, use 'context7' to get its documentation and understand its API."
  - rule: "For complex web scraping tasks during research, the 'firecrawl' tool can be used."

  # Development and Operations Rules
  - rule: "ALWAYS activate the virtual environment first before running any project commands, tests, or scripts."
  - rule: "The virtual environment is located at 'venv311' and must be activated using 'venv311\\Scripts\\activate' on Windows."
  - rule: "Incorporate the standard 'logging' module in all scripts and API endpoints. Log key events, errors, and performance metrics."
  - rule: "When providing code for standalone scripts, include the command to run it in a comment at the top of the file or in the instructions."
  - rule: "When troubleshooting, systematically use logs and debugging tools. Document the resolution in 'docs/troubleshooting.md'."

  # Implementation Status Rules
  - rule: "Week 1 is COMPLETED: Core histogram generation pipeline is fully implemented and tested."
  - rule: "The histogram generation module (src/chromatica/core/histogram.py) is production-ready with comprehensive validation."
  - rule: "Configuration management (src/chromatica/utils/config.py) is fully implemented with all required constants."
  - rule: "Testing infrastructure (tools/test_histogram_generation.py) is comprehensive and handles batch processing."
  - rule: "Current focus is Week 2: Implementing FAISS HNSW index and DuckDB metadata store."
  - rule: "All new code must integrate with existing histogram generation and configuration modules."

  # Testing and Validation Rules
  - rule: "Use the existing test datasets in datasets/ for development and validation across all phases: test-dataset-20 (quick testing), test-dataset-50 (validation), test-dataset-200 (performance), test-dataset-5000 (production-scale testing, renamed from test-dataset-999, recommended expansion to 7,500 images)."
  - rule: "The histogram testing tool generates 6 different report types for comprehensive analysis."
  - rule: "All histograms must pass validation: 1152 dimensions, L1 normalization, proper bounds."
  - rule: "Performance targets: ~200ms per image for histogram generation, 100% validation success rate."
  - rule: "Use the testing tool for validating new implementations before proceeding to next phases."
  - rule: "Follow dataset usage guidelines: test-dataset-20 for development, test-dataset-50/200 for validation, test-dataset-5000 for production-scale testing. Prioritize expanding test-dataset-5000 to 7,500 images for comprehensive evaluation."

  # Code Quality and Standards
  - rule: "All new functions must include comprehensive input validation and error handling."
  - rule: "Performance monitoring must be built into all new components (timing, memory usage)."
  - rule: "Error messages must be descriptive and actionable for debugging."
  - rule: "Logging must be implemented at appropriate levels (DEBUG, INFO, WARNING, ERROR)."
  - rule: "All new modules must include proper __init__.py files and import statements."

  # Integration Rules
  - rule: "New components must integrate seamlessly with existing histogram generation pipeline."
  - rule: "FAISS index implementation must use HNSW with M=32 as specified in configuration."
  - rule: "DuckDB implementation must support batch operations and efficient histogram retrieval."
  - rule: "All new code must follow the established project structure and naming conventions."
  - rule: "Dependencies must be added to requirements.txt with appropriate version constraints."
