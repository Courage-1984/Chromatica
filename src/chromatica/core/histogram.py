"""
Histogram generation module for the Chromatica color search engine.

This module provides the core functionality for converting images into color histograms
using the CIE Lab color space. The implementation follows the algorithmic specifications
from the critical instructions document, using tri-linear soft assignment to create
robust, normalized histograms suitable for color-based image search.

Key Features:
- Tri-linear soft assignment for robust histogram generation
- Vectorized operations using NumPy for performance
- L1 normalization to create probability distributions
- Support for the 8x12x12 binning grid (1,152 dimensions)

The histograms generated by this module are designed to work with the FAISS HNSW index
after applying the Hellinger transform, and with the Sinkhorn-EMD reranking stage.
"""

import numpy as np
from typing import Tuple
import logging

from ..utils.config import (
    L_BINS, A_BINS, B_BINS, TOTAL_BINS, LAB_RANGES
)

# Set up logging for this module
logger = logging.getLogger(__name__)


def build_histogram(lab_pixels: np.ndarray) -> np.ndarray:
    """
    Converts Lab pixels into a normalized, soft-assigned histogram.
    
    This function implements tri-linear soft assignment to distribute pixel counts
    across neighboring bins, creating a robust representation that is less sensitive
    to minor color variations. The final histogram is L1-normalized to create a
    probability distribution suitable for distance calculations.
    
    The function follows the algorithmic specification from Section E of the critical
    instructions, using the 8x12x12 binning grid over the CIE Lab color space.
    
    Mathematical Process:
    1. Convert Lab coordinates to continuous bin indices
    2. Calculate the fractional parts for tri-linear interpolation
    3. Distribute pixel counts to the 8 nearest bin centers using weights
    4. Flatten the 3D histogram to a 1D vector
    5. L1-normalize to create a probability distribution
    
    Args:
        lab_pixels: NumPy array of shape (N, 3) containing Lab color values.
                    Each row should contain [L*, a*, b*] values.
                    L* should be in range [0, 100]
                    a* should be in range [-86, 98]  
                    b* should be in range [-108, 95]
    
    Returns:
        np.ndarray: A flattened, L1-normalized histogram of shape (1152,).
                   The histogram represents the color distribution in the image
                   and sums to 1.0 (probability distribution).
    
    Raises:
        ValueError: If lab_pixels has incorrect shape or contains invalid Lab values.
        RuntimeError: If histogram normalization fails (e.g., all-zero histogram).
    
    Example:
        >>> # Assuming you have Lab pixels from an image
        >>> lab_pixels = np.array([[50.0, 10.0, -20.0], [80.0, -5.0, 15.0]])
        >>> histogram = build_histogram(lab_pixels)
        >>> print(f"Histogram shape: {histogram.shape}")
        >>> print(f"Sum of histogram: {histogram.sum():.6f}")
        Histogram shape: (1152,)
        Sum of histogram: 1.000000
    """
    # Input validation
    if lab_pixels.ndim != 2 or lab_pixels.shape[1] != 3:
        raise ValueError(
            f"lab_pixels must be a 2D array with shape (N, 3), got {lab_pixels.shape}"
        )
    
    if lab_pixels.size == 0:
        raise ValueError("lab_pixels cannot be empty")
    
    # Validate Lab value ranges
    l_vals, a_vals, b_vals = lab_pixels[:, 0], lab_pixels[:, 1], lab_pixels[:, 2]
    
    if np.any(l_vals < LAB_RANGES[0][0]) or np.any(l_vals > LAB_RANGES[0][1]):
        raise ValueError(
            f"L* values must be in range [{LAB_RANGES[0][0]}, {LAB_RANGES[0][1]}], "
            f"got range [{l_vals.min():.2f}, {l_vals.max():.2f}]"
        )
    
    if np.any(a_vals < LAB_RANGES[1][0]) or np.any(a_vals > LAB_RANGES[1][1]):
        raise ValueError(
            f"a* values must be in range [{LAB_RANGES[1][0]}, {LAB_RANGES[1][1]}], "
            f"got range [{a_vals.min():.2f}, {a_vals.max():.2f}]"
        )
    
    if np.any(b_vals < LAB_RANGES[2][0]) or np.any(b_vals > LAB_RANGES[2][1]):
        raise ValueError(
            f"b* values must be in range [{LAB_RANGES[2][0]}, {LAB_RANGES[2][1]}], "
            f"got range [{b_vals.min():.2f}, {b_vals.max():.2f}]"
        )
    
    logger.debug(f"Processing {lab_pixels.shape[0]} pixels for histogram generation")
    
    # Initialize the 3D histogram array
    hist = np.zeros((L_BINS, A_BINS, B_BINS), dtype=np.float32)
    
    # Calculate continuous bin indices for each pixel
    # This maps Lab values to continuous bin coordinates
    l_coords = (l_vals - LAB_RANGES[0][0]) / (LAB_RANGES[0][1] - LAB_RANGES[0][0]) * L_BINS
    a_coords = (a_vals - LAB_RANGES[1][0]) / (LAB_RANGES[1][1] - LAB_RANGES[1][0]) * A_BINS
    b_coords = (b_vals - LAB_RANGES[2][0]) / (LAB_RANGES[2][1] - LAB_RANGES[2][0]) * B_BINS
    
    # Get the integer bin indices (floor operation)
    # These represent the "lower-left" corner of the 8-neighbor cube
    l_idx = np.floor(l_coords).astype(int)
    a_idx = np.floor(a_coords).astype(int)
    b_idx = np.floor(b_coords).astype(int)
    
    # Calculate fractional parts for tri-linear interpolation
    # These represent the position within each bin (0.0 to 1.0)
    l_frac = l_coords - l_idx
    a_frac = a_coords - a_idx
    b_frac = b_coords - b_idx
    
    # Ensure indices are within valid bounds
    # This handles edge cases where values might be exactly at the boundary
    l_idx = np.clip(l_idx, 0, L_BINS - 2)
    a_idx = np.clip(a_idx, 0, A_BINS - 2)
    b_idx = np.clip(b_idx, 0, B_BINS - 2)
    
    # Tri-linear soft assignment: distribute each pixel to the 8 nearest bin centers
    # This creates a smooth histogram that's robust to minor color variations
    
    # For each pixel, we distribute its count (1.0) across 8 neighboring bins
    # using tri-linear interpolation weights
    for i in range(lab_pixels.shape[0]):
        # Get the base indices for this pixel
        l_base, a_base, b_base = l_idx[i], a_idx[i], b_idx[i]
        
        # Get the fractional parts for this pixel
        l_f, a_f, b_f = l_frac[i], a_frac[i], b_frac[i]
        
        # Calculate the 8 tri-linear weights
        # Each weight represents the contribution to one of the 8 neighboring bins
        w000 = (1 - l_f) * (1 - a_f) * (1 - b_f)  # Weight for (l_base, a_base, b_base)
        w001 = (1 - l_f) * (1 - a_f) * b_f        # Weight for (l_base, a_base, b_base + 1)
        w010 = (1 - l_f) * a_f * (1 - b_f)        # Weight for (l_base, a_base + 1, b_base)
        w011 = (1 - l_f) * a_f * b_f              # Weight for (l_base, a_base + 1, b_base + 1)
        w100 = l_f * (1 - a_f) * (1 - b_f)        # Weight for (l_base + 1, a_base, b_base)
        w101 = l_f * (1 - a_f) * b_f              # Weight for (l_base + 1, a_base, b_base + 1)
        w110 = l_f * a_f * (1 - b_f)              # Weight for (l_base + 1, a_base + 1, b_base)
        w111 = l_f * a_f * b_f                    # Weight for (l_base + 1, a_base + 1, b_base + 1)
        
        # Distribute the pixel count to the 8 neighboring bins
        # Each bin receives a fractional count based on the tri-linear weights
        hist[l_base, a_base, b_base] += w000
        hist[l_base, a_base, b_base + 1] += w001
        hist[l_base, a_base + 1, b_base] += w010
        hist[l_base, a_base + 1, b_base + 1] += w011
        hist[l_base + 1, a_base, b_base] += w100
        hist[l_base + 1, a_base, b_base + 1] += w101
        hist[l_base + 1, a_base + 1, b_base] += w110
        hist[l_base + 1, a_base + 1, b_base + 1] += w111
    
    # Flatten the 3D histogram to a 1D vector
    # This creates the 1,152-dimensional feature vector
    flat_hist = hist.flatten()
    
    # L1 normalization to create a probability distribution
    # This ensures the histogram sums to 1.0, making it suitable for distance calculations
    hist_sum = flat_hist.sum()
    
    if hist_sum == 0:
        raise RuntimeError(
            "Generated histogram is all zeros. This may indicate an issue with "
            "the input Lab values or the binning process."
        )
    
    # Normalize the histogram
    normalized_hist = flat_hist / hist_sum
    
    # Verify normalization
    if not np.isclose(normalized_hist.sum(), 1.0, atol=1e-6):
        logger.warning(
            f"Histogram normalization may have precision issues. "
            f"Sum: {normalized_hist.sum():.8f}, expected: 1.0"
        )
    
    logger.debug(
        f"Generated histogram with shape {normalized_hist.shape}, "
        f"sum: {normalized_hist.sum():.6f}, "
        f"min: {normalized_hist.min():.6f}, "
        f"max: {normalized_hist.max():.6f}"
    )
    
    return normalized_hist.astype(np.float32)


def build_histogram_fast(lab_pixels: np.ndarray) -> np.ndarray:
    """
    Fast approximation of histogram generation using simplified soft assignment.
    
    This is an alternative implementation that provides faster processing at the
    cost of some accuracy. It uses a simplified approach that assigns pixels
    to their nearest bin center rather than using full tri-linear interpolation.
    
    This function is useful for:
    - Quick prototyping and testing
    - Processing large datasets where speed is critical
    - Situations where the full tri-linear accuracy is not required
    
    Args:
        lab_pixels: NumPy array of shape (N, 3) containing Lab color values.
    
    Returns:
        np.ndarray: A flattened, L1-normalized histogram of shape (1152,).
    
    Note:
        This function uses the same validation and normalization as build_histogram
        but with simplified binning logic. For production use, prefer build_histogram.
    """
    # Input validation (same as build_histogram)
    if lab_pixels.ndim != 2 or lab_pixels.shape[1] != 3:
        raise ValueError(
            f"lab_pixels must be a 2D array with shape (N, 3), got {lab_pixels.shape}"
        )
    
    if lab_pixels.size == 0:
        raise ValueError("lab_pixels cannot be empty")
    
    # Validate Lab value ranges
    l_vals, a_vals, b_vals = lab_pixels[:, 0], lab_pixels[:, 1], lab_pixels[:, 2]
    
    if np.any(l_vals < LAB_RANGES[0][0]) or np.any(l_vals > LAB_RANGES[0][1]):
        raise ValueError(f"L* values out of range [{LAB_RANGES[0][0]}, {LAB_RANGES[0][1]}]")
    
    if np.any(a_vals < LAB_RANGES[1][0]) or np.any(a_vals > LAB_RANGES[1][1]):
        raise ValueError(f"a* values out of range [{LAB_RANGES[1][0]}, {LAB_RANGES[1][1]}]")
    
    if np.any(b_vals < LAB_RANGES[2][0]) or np.any(b_vals > LAB_RANGES[2][1]):
        raise ValueError(f"b* values out of range [{LAB_RANGES[2][0]}, {LAB_RANGES[2][1]}]")
    
    logger.debug(f"Processing {lab_pixels.shape[0]} pixels using fast histogram generation")
    
    # Initialize the 3D histogram array
    hist = np.zeros((L_BINS, A_BINS, B_BINS), dtype=np.float32)
    
    # Calculate continuous bin indices
    l_coords = (l_vals - LAB_RANGES[0][0]) / (LAB_RANGES[0][1] - LAB_RANGES[0][0]) * L_BINS
    a_coords = (a_vals - LAB_RANGES[1][0]) / (LAB_RANGES[1][1] - LAB_RANGES[1][0]) * A_BINS
    b_coords = (b_vals - LAB_RANGES[2][0]) / (LAB_RANGES[2][1] - LAB_RANGES[2][0]) * B_BINS
    
    # Round to nearest bin center (simplified approach)
    l_idx = np.clip(np.round(l_coords).astype(int), 0, L_BINS - 1)
    a_idx = np.clip(np.round(a_coords).astype(int), 0, A_BINS - 1)
    b_idx = np.clip(np.round(b_coords).astype(int), 0, B_BINS - 1)
    
    # Use numpy's add.at for efficient histogram building
    # This avoids potential issues with duplicate indices
    np.add.at(hist, (l_idx, a_idx, b_idx), 1)
    
    # Flatten and normalize
    flat_hist = hist.flatten()
    hist_sum = flat_hist.sum()
    
    if hist_sum == 0:
        raise RuntimeError("Generated histogram is all zeros")
    
    normalized_hist = flat_hist / hist_sum
    
    logger.debug(
        f"Generated fast histogram with shape {normalized_hist.shape}, "
        f"sum: {normalized_hist.sum():.6f}"
    )
    
    return normalized_hist.astype(np.float32)


def get_bin_centers() -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Get the center coordinates of each bin in the Lab color space.
    
    This function is useful for:
    - Visualizing the binning grid
    - Computing distance matrices for EMD calculations
    - Understanding the spatial distribution of bins
    
    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray]: 
            - l_centers: Array of L* bin centers
            - a_centers: Array of a* bin centers  
            - b_centers: Array of b* bin centers
    
    Example:
        >>> l_centers, a_centers, b_centers = get_bin_centers()
        >>> print(f"L* centers: {l_centers}")
        >>> print(f"a* centers: {a_centers}")
        >>> print(f"b* centers: {b_centers}")
    """
    l_centers = np.linspace(LAB_RANGES[0][0], LAB_RANGES[0][1], L_BINS)
    a_centers = np.linspace(LAB_RANGES[1][0], LAB_RANGES[1][1], A_BINS)
    b_centers = np.linspace(LAB_RANGES[2][0], LAB_RANGES[2][1], B_BINS)
    
    return l_centers, a_centers, b_centers


def get_bin_grid() -> np.ndarray:
    """
    Get the complete 3D grid of bin centers as a coordinate array.
    
    This function creates a meshgrid of all bin centers, which is useful for:
    - Computing cost matrices for EMD calculations
    - Visualizing the complete binning structure
    - Distance calculations between bins
    
    Returns:
        np.ndarray: Array of shape (1152, 3) where each row contains [L*, a*, b*]
                   coordinates of a bin center.
    
    Example:
        >>> bin_grid = get_bin_grid()
        >>> print(f"Bin grid shape: {bin_grid.shape}")
        >>> print(f"First few bin centers: {bin_grid[:5]}")
    """
    l_centers, a_centers, b_centers = get_bin_centers()
    
    # Create a 3D meshgrid and reshape to (1152, 3)
    grid = np.array(np.meshgrid(l_centers, a_centers, b_centers, indexing='ij'))
    bin_grid = grid.T.reshape(-1, 3)
    
    return bin_grid
